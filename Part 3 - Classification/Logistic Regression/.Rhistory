print("Hello world")
setwd("C:/Users/josue/Escritorio/MachineLearning/MachineLearning-For-DataScience/Part 3 - Classification/Logistic Regression")
library(ggplot2)
set <- training_set
Logística
Logística
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[,3:5]
#Dividir data set entre conjunto de entranamiento y testing
library(caTools)
set.seed(123) #Seleccionando semilla
#sample.split(Datos a separar, porcentaje para entrenar)
split = sample.split(dataset$Purchased,SplitRatio = 0.75)
#Separando datos de entrenamiento y testing
training_set = subset(dataset,split==TRUE)
testing_set = subset(dataset,split==FALSE)
#Escalado de valores
#[filas,columnas]
training_set[,1:2] = scale(training_set[,1:2])#[Todas las filas, de 2 a 3]
testing_set[,1:2] = scale(testing_set[,1:2])
# Ajustar el modelo de regresión logística con el conjunto de entrenamiento.
# Familia debe de ser binomial para regresion logistica
classifier = glm(formula = Purchased ~ .,
data = training_set,
family = binomial)
# Predicción de los resultados con el conjunto de testing
#Probabilidades de compra o no compra
prob_pred = predict(classifier, type = "response",
newdata = testing_set[,-3])
#Si en la probabilidad es mayor a 0.5 sera 1 (compra), caso contrarion 0 (no compra)
y_pred = ifelse(prob_pred> 0.5, 1, 0)
# Crear la matriz de confusión
cm = table(testing_set[, 3], y_pred)
library(ggplot2)
set <- training_set
X1 <- seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 <- seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set <- expand.grid(X1, X2)
colnames(grid_set) <- c('Age', 'EstimatedSalary')
prob_set <- predict(classifier, newdata = grid_set, type = 'response')
y_grid <- ifelse(prob_set > 0.5, 1, 0)
ggplot() +
geom_contour(data = data.frame(x = X1, y = X2, z = matrix(as.numeric(y_grid), length(X1), length(X2))),
aes(x = x, y = y, z = z),
bins = 10,
color = 'black',
alpha = 0.3,
size = 0.2) +
geom_point(data = grid_set,
aes(x = Age, y = EstimatedSalary, color = factor(y_grid)),
alpha = 0.1,
size = 0.2) +
geom_point(data = set,
aes(x = Age, y = EstimatedSalary, color = factor(Purchased)),
shape = 21,
fill = 'white',
size = 3) +
scale_color_manual(name = 'Predicción',
values = c('red3', 'springgreen3'),
labels = c('0', '1')) +
labs(title = 'Clasificación (Conjunto de Entrenamiento)',
x = 'Edad',
y = 'Sueldo Estimado',
color = 'Compra') +
xlim(range(X1)) +
ylim(range(X2))
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set <- expand.grid(X1, X2)
colnames(grid_set) <- c('Age', 'EstimatedSalary')
prob_set <- predict(classifier, newdata = grid_set, type = 'response')
y_grid <- ifelse(prob_set > 0.5, 1, 0)
ggplot() +
geom_contour(data = data.frame(x = X1, y = X2, z = matrix(as.numeric(y_grid), length(X1), length(X2))),
aes(x = x, y = y, z = z),
bins = 10,
color = 'black',
alpha = 0.3,
size = 0.2) +
geom_point(data = grid_set,
aes(x = Age, y = EstimatedSalary, color = factor(y_grid)),
alpha = 0.1,
size = 0.2) +
geom_point(data = set,
aes(x = Age, y = EstimatedSalary, color = factor(Purchased)),
shape = 21,
fill = 'white',
size = 3) +
scale_color_manual(name = 'Predicción',
values = c('red3', 'springgreen3'),
labels = c('0', '1')) +
labs(title = 'Clasificación (Conjunto de Entrenamiento)',
x = 'Edad',
y = 'Sueldo Estimado',
color = 'Compra') +
xlim(range(X1)) +
ylim(range(X2))
library(ggplot2)
set <- training_set
X1 <- seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 <- seq(min(set[, 2]) - 1, max(set[, 2]) + 1, length.out = length(X1))
grid_set <- expand.grid(X1, X2)
colnames(grid_set) <- c('Age', 'EstimatedSalary')
prob_set <- predict(classifier, newdata = grid_set, type = 'response')
y_grid <- ifelse(prob_set > 0.5, 1, 0)
ggplot() +
geom_contour(data = data.frame(x = X1, y = X2, z = matrix(as.numeric(y_grid), length(X1), length(X2))),
aes(x = x, y = y, z = z),
bins = 10,
color = 'black',
alpha = 0.3,
size = 0.2) +
geom_point(data = grid_set,
aes(x = Age, y = EstimatedSalary, color = factor(y_grid)),
alpha = 0.1,
size = 0.2) +
geom_point(data = set,
aes(x = Age, y = EstimatedSalary, color = factor(Purchased)),
shape = 21,
fill = 'white',
size = 3) +
scale_color_manual(name = 'Predicción',
values = c('red3', 'springgreen3'),
labels = c('0', '1')) +
labs(title = 'Clasificación (Conjunto de Entrenamiento)',
x = 'Edad',
y = 'Sueldo Estimado',
color = 'Compra') +
xlim(range(X1)) +
ylim(range(X2))
# Generar grid y clasificar puntos
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, length.out = length(X1))
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
prob_set = predict(classifier, type = 'response', newdata = grid_set)
y_grid = ifelse(prob_set > 0.5, 1, 0)
# Combinar datos en un dataframe
df <- cbind(grid_set, y_grid)
names(df) <- c("Age", "EstimatedSalary", "Class")
# Gráfico con ggplot2
ggplot(df, aes(x = Age, y = EstimatedSalary, z = Class)) +
geom_contour(aes(color = ..level..)) +
scale_color_gradient(low = "red3", high = "springgreen3", na.value = "grey50") +
geom_point(data = set, aes(x = Age, y = EstimatedSalary, color = factor(Purchased)),
shape = 21, size = 2) +
scale_color_manual(values = c("green4", "red3")) +
labs(title = "Clasificación (Conjunto de Entrenamiento)",
x = "Edad", y = "Sueldo Estimado")
